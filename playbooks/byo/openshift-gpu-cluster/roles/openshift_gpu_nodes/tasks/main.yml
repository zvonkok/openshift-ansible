---
- name: get the correct kernel-devel version from running kernel
  shell: echo kernel-devel-`uname -r`
  register: kernel_version

- name: try to install the same kernel-devel version as running kernel
  yum:
    name: "{{ kernel_version.stdout }}"

- name: Install epel repo from a remote rpm
  yum:
    name:  "{{ epel_repo }}"
    state: present


- name: Install NVIDIA repo from a remote rpm
  yum:
<<<<<<< HEAD
    name: "{{ cuda_repo }}"
=======
    name: https://developer.download.nvidia.com/compute/cuda/repos/rhel7/x86_64/cuda-repo-rhel7-9.2.88-1.x86_64.rpm
>>>>>>> bf471f17ca86be2ca3a68d47bd9f20728fb263ab
    state: present

- name: Install nvidia-driver
  yum:
    name: "{{ item }}"
    state: present
  with_items:
    "{{ nvidia_driver_rpms }}"


- name: add NVIDIA container repos
  yum_repository:
    name:          "{{ item.name }}"
    description:   NVIDIA container (docker) YUM repo
    file:          "{{ item.name }}"
    baseurl:       https://nvidia.github.io/{{ item.name }}/centos7/x86_64
    repo_gpgcheck: yes
    gpgcheck:      no
    gpgkey:        https://nvidia.github.io/{{ item.name }}/gpgkey
    sslverify:     yes
    sslcacert:     /etc/pki/tls/certs/ca-bundle.crt
  with_items:
    - { name: 'libnvidia-container' }
    - { name: 'nvidia-container-runtime' }

- name: import rpm keys
  rpm_key:
    state=present
    key={{ item }}
  with_items:
    - https://nvidia.github.io/nvidia-container-runtime/gpgkey
    - https://nvidia.github.io/libnvidia-container/gpgkey

- name: update repo cache for the new repo
  command: yum -q makecache -y --disablerepo=* --enablerepo={{ item }}
  with_items:
    - libnvidia-container
    - nvidia-container-runtime

- name: install nvidia-container-runtime-hook
  yum:
    name: nvidia-container-runtime-hook
    state: present
    update_cache: yes

- name: Remove nouveau
  command: modprobe -r nouveau

- name: Load nvidia modules
  command: nvidia-modprobe

- name: Load nvidia-uvm module
  command: nvidia-modprobe -u

- name: Check for GPU support
  command: nvidia-smi
  register: nsmi
  failed_when: "nsmi.rc != 0"

- name: set fact nvgpuname for future use
  set_fact: NV_GPU_NAME={{ "0xDEADBEEF" }}

- name: get NVIDIA GPU name
  shell: nvidia-smi --query-gpu=gpu_name --format=csv,noheader --id=0 | sed -e 's/ /-/g'
  register: nvgpuname

- name: set fact nvgpuname for future use
  set_fact: NV_GPU_NAME={{ nvgpuname.stdout }}

- name: restorecon var lib kubelet
  shell: restorecon -R -v /var/lib/kubelet

- name: restorecon dev
  shell: restorecon -R -v /dev

- name: restorecon nvidia-container-files
  shell: nvidia-container-cli -k list | restorecon -v -f -
